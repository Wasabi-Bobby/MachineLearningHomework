{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KerasLogisticRegressionProblem5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wasabi-Bobby/MachineLearningHomework/blob/master/KerasLogisticRegressionProblem5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "jntUVzj73IZG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "165f3b8a-42e4-42a4-d30d-c1d58535b89a"
      },
      "cell_type": "code",
      "source": [
        "# Pretty much taken from the notes that were done in class and posted on github\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = mnist.load_data()\n",
        "\n",
        "train_images = train_images_original.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QMQe2Tl-PKDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Syt3GHfLiihR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Flag is set to 0 if the current object is not continuous with white space, 1 if it is  \n",
        "def DFS_whitespace(x, y, flag):\n",
        "    if x < 0 or x > 27 or y < 0 or y > 27:\n",
        "      return 0\n",
        "    if visited_points[x][y] == 1:\n",
        "      return 0\n",
        "    if visited_points[x][y] == 0:\n",
        "      visited_points[x][y] = 1\n",
        "      DFS_whitespace(x+1, y, 1)\n",
        "      DFS_whitespace(x-1, y, 1)\n",
        "      DFS_whitespace(x, y+1, 1)\n",
        "      DFS_whitespace(x, y-1, 1)\n",
        "      if flag == 0:\n",
        "        return 1\n",
        "      return 0\n",
        "    \n",
        "def number_whitespace_count(number):\n",
        "  if number == 0:\n",
        "    return 2\n",
        "  if number == 1:\n",
        "    return 1\n",
        "  if number == 2:\n",
        "    return 1\n",
        "  if number == 3:\n",
        "    return 1\n",
        "  if number == 4:\n",
        "    return 2\n",
        "  if number == 5:\n",
        "    return 1\n",
        "  if number == 6:\n",
        "    return 2\n",
        "  if number == 7:\n",
        "    return 1\n",
        "  if number == 8:\n",
        "    return 3\n",
        "  if number == 9:\n",
        "    return 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ICjLiPcWPnAk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "train_images_rounded = np.copy(train_images)\n",
        "visited_points = np.zeros((28, 28))\n",
        "whitespace_train_matrix = np.zeros((60000, 10))\n",
        "\n",
        "for i in range(len(train_images_rounded)):\n",
        "  visited_points = np.zeros((28, 28))\n",
        "  \n",
        "  for j in range(len(train_images_rounded[i])):\n",
        "    if train_images_rounded[i][j] > 0.5:\n",
        "      train_images_rounded[i][j] = 1.0\n",
        "      x = y = 0\n",
        "      x = (int)(j/28)\n",
        "      y = (int)(j%28)\n",
        "      visited_points[x][y] = 1\n",
        "    else:\n",
        "      train_images_rounded[i][j] = 0.0\n",
        "  \n",
        "  white_space_current_count = 0\n",
        "  \n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      white_space_current_count += DFS_whitespace(j, k, 0)\n",
        "      \n",
        "  for j in range(10):\n",
        "    if white_space_current_count == number_whitespace_count(j):\n",
        "      whitespace_train_matrix[i][j] = 1\n",
        "    else:\n",
        "      whitespace_train_matrix[i][j] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56WAFG11q6gg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "test_images_rounded = np.copy(test_images)\n",
        "visited_points = np.zeros((28, 28))\n",
        "whitespace_test_matrix = np.zeros((10000, 10))\n",
        "\n",
        "for i in range(len(test_images_rounded)):\n",
        "  visited_points = np.zeros((28, 28))\n",
        "  \n",
        "  for j in range(len(test_images_rounded[i])):\n",
        "    if test_images_rounded[i][j] > 0.5:\n",
        "      test_images_rounded[i][j] = 1.0\n",
        "      x = y = 0\n",
        "      x = (int)(j/28)\n",
        "      y = (int)(j%28)\n",
        "      visited_points[x][y] = 1\n",
        "    else:\n",
        "      test_images_rounded[i][j] = 0.0\n",
        "  \n",
        "  white_space_current_count = 0\n",
        "  \n",
        "  for j in range(28):\n",
        "    for k in range(28):\n",
        "      white_space_current_count += DFS_whitespace(j, k, 0)\n",
        "  \n",
        "  for j in range(10):\n",
        "    if white_space_current_count == number_whitespace_count(j):\n",
        "      whitespace_test_matrix[i][j] = 1\n",
        "    else:\n",
        "      whitespace_test_matrix[i][j] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tq8KZbG91TZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "whitespace_test_matrix = whitespace_test_matrix.reshape((10000, 10))\n",
        "whitespace_train_matrix = whitespace_train_matrix.reshape((60000, 10))\n",
        "\n",
        "whitespace_test_matrix = whitespace_test_matrix.astype('float32')\n",
        "whitespace_train_matrix = whitespace_train_matrix.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "77mSaCKX3Sao",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "6bc78875-36bd-496a-e95b-30027e1d7cfe"
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "# input1 = layers.Input(shape=(28 * 28,))\n",
        "# x1 = layers.Dense(512, activation='relu')(input1)\n",
        "# input2 = layers.Input(shape=(10,))\n",
        "# x2 = layers.Dense(512, activation='relu')(input2)\n",
        "# equivalent to added = keras.layers.add([x1, x2])\n",
        "# added = layers.Add()([x1, x2])\n",
        "\n",
        "network = models.Sequential()\n",
        "\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
        "network.add(layers.Dense(512, activation='relu', input_shape=(10,)))\n",
        "#network.add(added)\n",
        "network.add(layers.Dense(10, activation='softmax'))\n",
        "network.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 669,706\n",
            "Trainable params: 669,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bhFzbGeZ5jjC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "0e7b4d1e-dce5-4f9b-c116-9ff80dfed080"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "main_input = Input(shape=(28*28,), dtype='float32', name='main_input')\n",
        "x = Embedding(output_dim=512, input_dim=60000, input_length=784)(main_input)\n",
        "lstm_out = LSTM(128)(x)\n",
        "\n",
        "auxiliary_output = Dense(1, activation='softmax', name='aux_output')(lstm_out)\n",
        "\n",
        "auxiliary_input = Input(shape=(10,), name='aux_input')\n",
        "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
        "\n",
        "x = Dense(128, activation='relu')(x)\n",
        "\n",
        "main_output = Dense(1, activation='softmax', name='main_output')(x)\n",
        "\n",
        "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
        "\n",
        "#model.compile(optimizer='rmsprop',\n",
        "#                loss='categorical_crossentropy',\n",
        "#                metrics=['accuracy'])\n",
        "\n",
        "#model.fit([train_labels, whitespace_train_matrix], [train_labels, train_labels],\n",
        "#          epochs=10, batch_size=128)\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'},\n",
        "              loss_weights={'main_output': 1., 'aux_output': 0.2})\n",
        "\n",
        "# And trained it via:\n",
        "model.fit({'main_input': train_labels, 'aux_input': whitespace_train_matrix},\n",
        "          {'main_output': train_labels, 'aux_output': train_labels},\n",
        "          epochs=50, batch_size=128)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-cd9d5bc3a744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m model.fit({'main_input': train_labels, 'aux_input': whitespace_train_matrix},\n\u001b[1;32m     33\u001b[0m           \u001b[0;34m{\u001b[0m\u001b[0;34m'main_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aux_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m           epochs=50, batch_size=128)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected main_input to have shape (784,) but got array with shape (10,)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "UssCsav13VGH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network.compile(optimizer='rmsprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ss-1jqBd3XIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "5beb7563-ac15-4077-f985-00560a1c3719"
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = network.fit([train_images,\n",
        "                      whitespace_train_matrix],\n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-de9105ea72ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       validation_data=(test_images, test_labels))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0...."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "giSk6T-B3dyX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "b154a1c3-c8b2-44f9-e503-9d5c6eeffaae"
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = network.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs, \n",
        "                      batch_size=128, \n",
        "                      validation_data=(test_images, test_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0075 - acc: 0.9980 - val_loss: 0.0838 - val_acc: 0.9789\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0803 - val_acc: 0.9810\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0894 - val_acc: 0.9807\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0786 - val_acc: 0.9824\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0848 - val_acc: 0.9807\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0831 - val_acc: 0.9835\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0828 - val_acc: 0.9825\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0967 - val_acc: 0.9800\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0920 - val_acc: 0.9826\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0928 - val_acc: 0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1spcU4Q-3yp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9619542-a086-4376-d778-729dff640d43"
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "test_acc_values = history_dict['val_acc']\n",
        "#prints out the last test value after the 10 testing epochs\n",
        "print(test_acc_values[epochs - 1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9825\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}