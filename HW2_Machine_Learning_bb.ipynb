{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2 Machine Learning bb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wasabi-Bobby/MachineLearningHomework/blob/master/HW2_Machine_Learning_bb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lVUScIxVfIBY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(train_images_original, train_labels_original), (test_images_original, test_labels_original) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dJE3NKMcxD96",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preparing image and labels\n",
        "-------------\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oxuHgrrRxxp_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64b10ffa-29e2-4aa3-91f0-1b56c8007fb2"
      },
      "cell_type": "code",
      "source": [
        "train_images_original.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "smLtkeDax0Cw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0c5bdeb0-744d-4c1d-b36e-9ef948bf1284"
      },
      "cell_type": "code",
      "source": [
        "test_images_original.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "-VQeFmzdxFnb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_images = train_images_original.reshape((50000, 32, 32, 3))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images_original.reshape((10000, 32, 32, 3))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dfvzqV1kyCPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels_original)\n",
        "test_labels = to_categorical(test_labels_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZpH3CBWvd2O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some nice code snippet i found for shuffling two arrays on github. Link -> https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison"
      ]
    },
    {
      "metadata": {
        "id": "9ujASf_Jvmhm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def unison_shuffled_copies(a, b):\n",
        "    assert len(a) == len(b)\n",
        "    p = np.random.permutation(len(a))\n",
        "    return a[p], b[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2szCyhA7v9uN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing this just in case\n",
        "----------------------------\n",
        "It works!"
      ]
    },
    {
      "metadata": {
        "id": "HetbbDSov_eu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "04e3af3d-9942-4c84-8717-9288b4f06908"
      },
      "cell_type": "code",
      "source": [
        "x = np.array([1,2,3,4])\n",
        "y = np.array([1,2,3,4])\n",
        "random_x, random_y = unison_shuffled_copies(x, y)\n",
        "print(random_x)\n",
        "print(random_y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1 3 4]\n",
            "[2 1 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7cXZQXMfuW6A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Shuffling step + Validation set\n",
        "--------------------\n",
        "Creating Validation and Test set from the data (Not k-fold iteration kind of validation)\n",
        "\n",
        "Actually going to ignore this valid set section for now since keras has a way to set the percentage of a validation set..."
      ]
    },
    {
      "metadata": {
        "id": "7FfFSwdauC1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Shuffling array\n",
        "random_train_images, random_train_labels = unison_shuffled_copies(train_images, train_labels)\n",
        "#valid_set = [(random_train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZB6VOq2zitf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Network Architecture 1\n",
        "----------------------------\n",
        "Just going to have about 4 convolutional layers and do four max pools\n",
        "\n",
        "Basic architecture"
      ]
    },
    {
      "metadata": {
        "id": "Z2vVDZNgziYZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "30f79aca-f166-4b4a-d2b4-b3192e46ad32"
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model_one = models.Sequential()\n",
        "model_one.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "#model_one.add(layers.MaxPooling2D((2, 2)))\n",
        "model_one.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "#model_one.add(layers.MaxPooling2D(2, 2))\n",
        "model_one.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model_one.add(layers.Flatten())\n",
        "model_one.add(layers.Dense(64, activation='relu'))\n",
        "model_one.add(layers.Dense(10, activation='softmax'))\n",
        "model_one.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 26, 26, 64)        36928     \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 43264)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                2768960   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 2,825,930\n",
            "Trainable params: 2,825,930\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-lTY6U_NA_N6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Network Architecture 2\n",
        "---------------------------\n",
        "Now with maxpooling!"
      ]
    },
    {
      "metadata": {
        "id": "0FTduNm3A-kJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "1e5d75cc-22e0-482d-8bfa-a8e48f6e4758"
      },
      "cell_type": "code",
      "source": [
        "model_two = models.Sequential()\n",
        "model_two.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "model_two.add(layers.MaxPooling2D((2, 2)))\n",
        "model_two.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_two.add(layers.MaxPooling2D(2, 2))\n",
        "model_two.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_two.add(layers.MaxPooling2D(2, 2))\n",
        "model_two.add(layers.Flatten())\n",
        "model_two.add(layers.Dense(64, activation='relu'))\n",
        "model_two.add(layers.Dense(10, activation='softmax'))\n",
        "model_two.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_34 (Conv2D)           (None, 30, 30, 16)        448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_22 (MaxPooling (None, 15, 15, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 13, 13, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 6, 6, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 4, 4, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 2, 2, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 23,242\n",
            "Trainable params: 23,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EZ8_TJGIDmza",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Network Architecture 3, 4, 5, 6\n",
        "-----------------------------\n",
        "Just kinda messing around with different layers and pooling and the epochs should be 5 for each"
      ]
    },
    {
      "metadata": {
        "id": "ifpfgpjNEGJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "858d2bbf-3fed-4ae4-e949-b1040a238514"
      },
      "cell_type": "code",
      "source": [
        "model_three = models.Sequential()\n",
        "#massive filter for the first layer\n",
        "model_three.add(layers.Conv2D(64, (9, 9), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "model_three.add(layers.MaxPooling2D((2, 2)))\n",
        "model_three.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_three.add(layers.MaxPooling2D(2, 2))\n",
        "model_three.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_three.add(layers.MaxPooling2D(2, 2))\n",
        "model_three.add(layers.Flatten())\n",
        "model_three.add(layers.Dense(64, activation='relu'))\n",
        "model_three.add(layers.Dense(10, activation='softmax'))\n",
        "model_three.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_58 (Conv2D)           (None, 24, 24, 64)        15616     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 10, 10, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_60 (Conv2D)           (None, 3, 3, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 46,090\n",
            "Trainable params: 46,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eQzK0r0ME9Q4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "f2187dd5-0b9d-44d1-a618-f309a35133d9"
      },
      "cell_type": "code",
      "source": [
        "model_four = models.Sequential()\n",
        "model_four.add(layers.Conv2D(128, (9, 9), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "model_four.add(layers.MaxPooling2D((2, 2)))\n",
        "model_four.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_four.add(layers.MaxPooling2D(2, 2))\n",
        "model_four.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_four.add(layers.MaxPooling2D(2, 2))\n",
        "model_four.add(layers.Flatten())\n",
        "model_four.add(layers.Dense(64, activation='relu'))\n",
        "model_four.add(layers.Dense(10, activation='softmax'))\n",
        "model_four.summary()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_43 (Conv2D)           (None, 24, 24, 128)       31232     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 10, 10, 32)        36896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 3, 3, 32)          9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling (None, 1, 1, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 80,138\n",
            "Trainable params: 80,138\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2XQXK0HhE721",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_five = models.Sequential()\n",
        "model_five.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "model_five.add(layers.MaxPooling2D((2, 2)))\n",
        "model_five.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_five.add(layers.MaxPooling2D(2, 2))\n",
        "model_five.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_five.add(layers.MaxPooling2D(2, 2))\n",
        "model_five.add(layers.Flatten())\n",
        "model_five.add(layers.Dense(64, activation='relu'))\n",
        "model_five.add(layers.Dense(10, activation='softmax'))\n",
        "model_five.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQgKjW91E6Cq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_six = models.Sequential()\n",
        "model_six.add(layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3), data_format=\"channels_last\"))\n",
        "model_six.add(layers.MaxPooling2D((2, 2)))\n",
        "model_six.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_six.add(layers.MaxPooling2D(2, 2))\n",
        "model_six.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model_six.add(layers.MaxPooling2D(2, 2))\n",
        "model_six.add(layers.Flatten())\n",
        "model_six.add(layers.Dense(64, activation='relu'))\n",
        "model_six.add(layers.Dense(10, activation='softmax'))\n",
        "model_six.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NR3b80nz2dxD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compilation\n",
        "------------------------------"
      ]
    },
    {
      "metadata": {
        "id": "FU6ZLBz62Ynw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_one.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Brfh48njA21f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_two.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ozMC0u3eHEvg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_three.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIOTUVsr2g2T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training without k-fold\n",
        "----------------------------"
      ]
    },
    {
      "metadata": {
        "id": "BVlFaKpE2gvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "96f1649c-21c2-4a90-fda1-8639dfd66a48"
      },
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "history_one = model_one.fit(train_images,\n",
        "                           train_labels,\n",
        "                           epochs=epochs,\n",
        "                           validation_split=0.2,\n",
        "                           batch_size=128)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 390s 10ms/step - loss: 1.4529 - acc: 0.4867 - val_loss: 1.2170 - val_acc: 0.5673\n",
            "Epoch 2/5\n",
            "40000/40000 [==============================] - 372s 9ms/step - loss: 1.0914 - acc: 0.6191 - val_loss: 1.1139 - val_acc: 0.6097\n",
            "Epoch 3/5\n",
            "40000/40000 [==============================] - 369s 9ms/step - loss: 0.8519 - acc: 0.7058 - val_loss: 1.0577 - val_acc: 0.6443\n",
            "Epoch 4/5\n",
            "40000/40000 [==============================] - 367s 9ms/step - loss: 0.6471 - acc: 0.7780 - val_loss: 1.1251 - val_acc: 0.6357\n",
            "Epoch 5/5\n",
            "40000/40000 [==============================] - 369s 9ms/step - loss: 0.4483 - acc: 0.8474 - val_loss: 1.4075 - val_acc: 0.6073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1nHHw6hyBp8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "af1bc417-6c43-4d8b-e4f4-7593f820a95e"
      },
      "cell_type": "code",
      "source": [
        "history_two = model_two.fit(train_images,\n",
        "                           train_labels,\n",
        "                           epochs=epochs,\n",
        "                           validation_split=0.2,\n",
        "                           batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "40000/40000 [==============================] - 41s 1ms/step - loss: 1.9268 - acc: 0.2929 - val_loss: 1.7724 - val_acc: 0.3409\n",
            "Epoch 2/5\n",
            "25728/40000 [==================>...........] - ETA: 12s - loss: 1.6677 - acc: 0.3996"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_SBeq5yEC4-s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "4865d449-a305-45b5-99f0-321c1848bf72"
      },
      "cell_type": "code",
      "source": [
        "epochs_three = 20\n",
        "history_three = model_two.fit(train_images,\n",
        "                           train_labels,\n",
        "                           epochs=epochs_three,\n",
        "                           validation_split=0.2,\n",
        "                           batch_size=128)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.2700 - acc: 0.5522 - val_loss: 1.2842 - val_acc: 0.5500\n",
            "Epoch 2/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.2223 - acc: 0.5657 - val_loss: 1.1702 - val_acc: 0.5901\n",
            "Epoch 3/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.1720 - acc: 0.5877 - val_loss: 1.2134 - val_acc: 0.5681\n",
            "Epoch 4/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.1348 - acc: 0.6003 - val_loss: 1.1962 - val_acc: 0.5805\n",
            "Epoch 5/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.1028 - acc: 0.6116 - val_loss: 1.1944 - val_acc: 0.5804\n",
            "Epoch 6/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.0706 - acc: 0.6232 - val_loss: 1.2581 - val_acc: 0.5650\n",
            "Epoch 7/20\n",
            "40000/40000 [==============================] - 41s 1ms/step - loss: 1.0433 - acc: 0.6342 - val_loss: 1.1173 - val_acc: 0.6112\n",
            "Epoch 8/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 1.0161 - acc: 0.6419 - val_loss: 1.1592 - val_acc: 0.6016\n",
            "Epoch 9/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.9901 - acc: 0.6530 - val_loss: 1.0704 - val_acc: 0.6302\n",
            "Epoch 10/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.9703 - acc: 0.6597 - val_loss: 1.1610 - val_acc: 0.6012\n",
            "Epoch 11/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.9509 - acc: 0.6652 - val_loss: 1.0752 - val_acc: 0.6285\n",
            "Epoch 12/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.9296 - acc: 0.6728 - val_loss: 1.1514 - val_acc: 0.6037\n",
            "Epoch 13/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.9105 - acc: 0.6815 - val_loss: 1.2135 - val_acc: 0.5807\n",
            "Epoch 14/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8962 - acc: 0.6851 - val_loss: 1.1567 - val_acc: 0.6126\n",
            "Epoch 15/20\n",
            "40000/40000 [==============================] - 41s 1ms/step - loss: 0.8799 - acc: 0.6919 - val_loss: 1.0256 - val_acc: 0.6473\n",
            "Epoch 16/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8637 - acc: 0.6967 - val_loss: 1.0475 - val_acc: 0.6399\n",
            "Epoch 17/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8532 - acc: 0.6990 - val_loss: 1.0492 - val_acc: 0.6401\n",
            "Epoch 18/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8370 - acc: 0.7066 - val_loss: 1.0018 - val_acc: 0.6530\n",
            "Epoch 19/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8239 - acc: 0.7111 - val_loss: 1.0365 - val_acc: 0.6505\n",
            "Epoch 20/20\n",
            "40000/40000 [==============================] - 42s 1ms/step - loss: 0.8104 - acc: 0.7170 - val_loss: 1.0444 - val_acc: 0.6443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CUx7JEBFHOx8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_four = model_two.fit(train_images,\n",
        "                           train_labels,\n",
        "                           epochs=epochs,\n",
        "                           validation_split=0.2,\n",
        "                           batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UjuNpmkW3b66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Graphs\n",
        "--------------"
      ]
    },
    {
      "metadata": {
        "id": "g3z_35FR3eDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict_one = history_one.history\n",
        "loss_values_one = history_dict_one['loss']\n",
        "test_loss_values_one = history_dict_one['val_loss']\n",
        "epochs_range_one = range(1, epochs + 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1xVKaaV-cAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "6a3a232b-800f-490a-9bc0-7081c205236a"
      },
      "cell_type": "code",
      "source": [
        "acc_values_one = history_dict_one['acc']\n",
        "test_acc_values_one = history_dict_one['val_acc']\n",
        "\n",
        "plt.plot(epochs_range_one, acc_values_one, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs_range_one, test_acc_values_one, 'ro', label='Test accuracy')\n",
        "plt.title('Training and test accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAFnCAYAAAC/5tBZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRtzR8BsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "3TkQn6aa_2r6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Does well on the validation set, but the test accuracy starts to fall with later epochs.\n",
        "\n",
        "Model with only a filter and no maxpooling performs very slowly and poorly"
      ]
    }
  ]
}